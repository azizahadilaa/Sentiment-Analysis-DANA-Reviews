{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34e953ec",
   "metadata": {},
   "source": [
    "# Phase 2: Data Preprocessing & Cleaning\n",
    "\n",
    "> **Author:** Azizah Adilah\n",
    "\n",
    "> **Date:** January 2026\n",
    "\n",
    "> **Goal:** Transform raw text into a clean format suitable for sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee5861a",
   "metadata": {},
   "source": [
    "### **Import Libraries**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f34def",
   "metadata": {},
   "source": [
    "#### **Step 1: Import Libraries and Load Raw Data**\n",
    "In this initial step, I import the necessary Python libraries for data manipulation (`pandas`), text processing (`re`, `string`), and Indonesian language processing (`Sastrawi`). I also load the raw dataset collected from the web scraping phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c860d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lumayan TPI kadang erorr sampah</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sangat buruk pelayananya baru beberapa hari ap...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>luar biasa berguna</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bagus</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sangat baik</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  score\n",
       "0                    lumayan TPI kadang erorr sampah      5\n",
       "1  sangat buruk pelayananya baru beberapa hari ap...      1\n",
       "2                                 luar biasa berguna      5\n",
       "3                                              bagus      5\n",
       "4                                        sangat baik      5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "# Use library Sastrawi for bahasa Indonesia\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "# Load data \n",
    "df = pd.read_csv('../data/reviews_dana_raw.csv')\n",
    "\n",
    "# Only use column 'content' and 'score'\n",
    "df = df[['content', 'score']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d798a94",
   "metadata": {},
   "source": [
    "### Data Observation & Slang Identification\n",
    "Before proceeding with cleaning, I performed a manual inspection and word frequency analysis to identify common slangs and issues in DANA reviews:\n",
    "\n",
    "* **Top Issues Identified:** Transaction errors (saldo hilang), DANA Cicil functionality, and login loops after updates.\n",
    "* **Slang Discoveries:** Found various abbreviations like 'ccln' (cicilan), 'kbnykn' (kebanyakan), and 'ndak' (tidak).\n",
    "* **Business Insight:** There is a high volume of discussion regarding 'DANA Cicil' and 'Paylater' features, often associated with negative sentiment when the features are unavailable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b4a205",
   "metadata": {},
   "source": [
    "### **Cleaning Function**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b18729",
   "metadata": {},
   "source": [
    "#### **Step 2: General Text Cleaning**\n",
    "The goal of this step is to standardize the text. The `clean_text` function performs:\n",
    "* **Lowercasing**: Converting all text to lowercase to ensure uniformity.\n",
    "* **Removing Special Characters**: Eliminating numbers, punctuation, and symbols that do not contribute to sentiment analysis.\n",
    "* **Whitespace Removal**: Cleaning up unnecessary spaces for better tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8598fdbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>content_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lumayan TPI kadang erorr sampah</td>\n",
       "      <td>5</td>\n",
       "      <td>lumayan tpi kadang erorr sampah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sangat buruk pelayananya baru beberapa hari ap...</td>\n",
       "      <td>1</td>\n",
       "      <td>sangat buruk pelayananya baru beberapa hari ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>luar biasa berguna</td>\n",
       "      <td>5</td>\n",
       "      <td>luar biasa berguna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bagus</td>\n",
       "      <td>5</td>\n",
       "      <td>bagus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sangat baik</td>\n",
       "      <td>5</td>\n",
       "      <td>sangat baik</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  score  \\\n",
       "0                    lumayan TPI kadang erorr sampah      5   \n",
       "1  sangat buruk pelayananya baru beberapa hari ap...      1   \n",
       "2                                 luar biasa berguna      5   \n",
       "3                                              bagus      5   \n",
       "4                                        sangat baik      5   \n",
       "\n",
       "                                       content_clean  \n",
       "0                    lumayan tpi kadang erorr sampah  \n",
       "1  sangat buruk pelayananya baru beberapa hari ap...  \n",
       "2                                 luar biasa berguna  \n",
       "3                                              bagus  \n",
       "4                                        sangat baik  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    # Lowercasing\n",
    "    text = str(text).lower()\n",
    "    # Remove number and symbol\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove extra whitespace\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "df['content_clean'] = df['content'].apply(clean_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0da3f6",
   "metadata": {},
   "source": [
    "### **Top Words Checking**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d9d2e2",
   "metadata": {},
   "source": [
    "#### **Step 3: Top Words Frequency Check**\n",
    "Before applying any heavy processing, I analyze the word frequency distribution of the initial cleaned text. This quantitative step helps identify the most dominant words, including potential slang, abbreviations, and common stopwords that need to be addressed in the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17c717e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dana', 312), ('di', 224), ('bisa', 194), ('sangat', 189), ('saya', 180), ('bagus', 137), ('tidak', 120), ('aplikasi', 118), ('dan', 113), ('nya', 102), ('ini', 102), ('ada', 91), ('membantu', 84), ('mantap', 66), ('cicil', 65), ('udah', 61), ('buka', 58), ('gak', 57), ('sudah', 55), ('saldo', 54), ('kenapa', 52), ('transaksi', 51), ('ga', 49), ('ke', 48), ('mau', 47), ('lagi', 46), ('baik', 45), ('apk', 45), ('untuk', 45), ('ok', 43), ('masuk', 43), ('uang', 43), ('tapi', 42), ('yang', 42), ('ya', 39), ('gk', 38), ('mudah', 38), ('aja', 36), ('padahal', 36), ('sekali', 35), ('akun', 35), ('cepat', 33), ('malah', 33), ('tolong', 32), ('baru', 31), ('terus', 31), ('sekarang', 29), ('banget', 28), ('masih', 28), ('sering', 27)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Gabungkan semua ulasan jadi satu teks besar\n",
    "all_text = ' '.join(df['content_clean'].astype(str))\n",
    "words = all_text.split()\n",
    "\n",
    "# Hitung 50 kata paling sering muncul\n",
    "top_words = Counter(words).most_common(50)\n",
    "print(top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37d6f41",
   "metadata": {},
   "source": [
    "### **Manual Sampling** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925bc711",
   "metadata": {},
   "source": [
    "#### **Step 4: Manual Data Sampling**\n",
    "While frequency checks are useful, they lack context. In this step, I perform a qualitative review by sampling random rows of the raw reviews. This helps me understand the \"flavor\" of user languageâ€”how they express frustration, praise, and technical issues in their own words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c81c14d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Manual Sampling (Raw Content) ---\n",
      "1. alhamdulillah klw punya aplikasi dana smua mudah dari apa aja semua serba bisa  trimakasih dana\n",
      "2. the beast\n",
      "3. good job team thanks\n",
      "4. bagus\n",
      "5. cukup membantu\n",
      "6. sangat memuaskan\n",
      "7. terbaik\n",
      "8. sangat baik\n",
      "9. semoga cepet muncul pitur dana cicil nya\n",
      "10. mantap\n"
     ]
    }
   ],
   "source": [
    "# Seeing 10 random examples of original reviews\n",
    "print(\"--- Manual Sampling (Raw Content) ---\")\n",
    "samples = df['content_clean'].sample(10).values\n",
    "for i, sample in enumerate(samples):\n",
    "    print(f\"{i+1}. {sample}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbb82b9",
   "metadata": {},
   "source": [
    "### **Checking the context of specific words**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d174952",
   "metadata": {},
   "source": [
    "#### **Step 5: Contextual Investigation for Specific Keywords**\n",
    "Based on the top words and manual samples, I investigate specific \"high-signal\" keywords (e.g., 'cicil', 'saldo', 'login'). This investigation reveals deep business insights, such as recurring technical bugs or specific feature dissatisfaction, which are crucial for the final business analysis report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d966b49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Context for: cicil ===\n",
      "1. tolol apklikasi udh d munculin ccln masa iya blm dpt dan cicilan bertahap mengecewakan off pakai dana skrng dah kbnykn potong bertahunx pakai mengecewakan cuihhhh ganti yg lain juga bnyk g rugi juga g pakai dana orang dah bnyk gopay shopee pay juga ada udh paylater lg\n",
      "2. fitur dana cicil fungsi nya apa klo ga bisa di gunain walau limit ada ga bisa bayar apapun di hapus aj ga guna\n",
      "3. tolong dana cicil\n",
      "4. blum pernah nyicil tiba tiba banyak cicilan dana gak jelas sekarang banyak pungli haram\n",
      "5. kenapa dana saya tida ada cicill\n",
      "\n",
      "=== Context for: saldo ===\n",
      "1. apk dana tidak bisa di buka padahal jaringan enak nanti ujungnya saldo hangus tolong di perbaikin\n",
      "2. saya sangat kecewa kepada dana semua sudah di lakukan tapi saldo nya tidak ada  uang raibhilang di rekening dana lapor admin jawabannya ngambang sepertinya aplikasi ini tidak aman lagi  kecewa berat bukti transfer ada tapi saldo hilang begitu aja lapor cs menunggu berharihari padahal uang ny mau di gunakan untuk bayar utang\n",
      "3. parah ini dana gabisa chat minta bantuan di apk nya udah bahaya tiap jam  subuh selalu ada notip lanjutkan pembayaran dari google nominal  apa coba kaya nya klo ada saldo jt ke sedot sendiri tuh saldo gabisa di batalin padahal bukan transaksi saya tiba tiba notip nya ga bisa di apa apain gajelas tiap hari notip nya selalu ada pas di klik otomatis suruh isi saldo melalui bank lain\n",
      "4. transfer tengah malam transaksi berhasilpas di cek ke atm saldoa tetep gk adagmn ne pertanggung jawabannyadikira gampang cari uang\n",
      "5. kok makin aneh ni apl danadana cicil nya saya sudah bayar lunastapi masih ak di tagih dan di sedot saldo sayadan saya sudah chat buat berulang kali laporan tapi masih blom ad solusinyamasih aj saldo saya di sedot\n",
      "\n",
      "=== Context for: login ===\n",
      "1. kenapa saya tidak masuk ke akun dana saya  udah  hari muterÂ² saja gk bisa login\n",
      "2. kenapa ga bisa login sdh seminggu ini mau login ke dana ga bisa dikirimin email dari tgl  januari jg ga ada respon admin dana sama sekali ga profesional\n",
      "3. mw login ny susah\n",
      "4. ini kenpa dari kemaren mau login g bisa\n",
      "5. aplikasi ndak jelas  akun kena jaringan bermasalah terus  udah premium satunya nyoba buat akun baru malah kena juga ngga ngapa ngapain aja ngga bisa login\n",
      "\n",
      "=== Context for: kecewa ===\n",
      "1. saya sangat kecewa kepada dana semua sudah di lakukan tapi saldo nya tidak ada  uang raibhilang di rekening dana lapor admin jawabannya ngambang sepertinya aplikasi ini tidak aman lagi  kecewa berat bukti transfer ada tapi saldo hilang begitu aja lapor cs menunggu berharihari padahal uang ny mau di gunakan untuk bayar utang\n",
      "2. aplikasi pencuri dana  laporan sukses tapi tidak masuk cs lambat berharihari tidak ada kejelasan kecewa ðŸ˜œðŸ¤ªðŸ˜‹\n",
      "3. saya kecewa sama dana masa dana cicil tidak bisa di gunakan tulisannya tidak tersedia padahal buat beli pulsa dan coba di warung juga sama aja tidak bisa di gunakan chat diana malah gk jelas disuruh ke pusat bantuan gliran udah di pusat bantuan malah di puter jawabannya  tolong perbaiki lagi systemnya klo udh normal dana cicilnya saya tambahin bintangnyaterima kasih\n",
      "4. saya kasih bintang  sangat kecewa dengan aplikasi ini setiap kali dibuka tiba tiba layar hitam lalu putih terus keluar aplikasi yang sangat merugikan banyak pihak dan pengguna kepada developer jika tidak ada niat perbaikan alangkah baiknya jika aplikasinya dimusnahkan hapus saja karena sangat merugikan kami para pengguna dana dari sejak lama\n",
      "5. kecewa saldo saya hilang sendiri\n",
      "\n",
      "=== Context for: update ===\n",
      "1. tidak bisa update dan tidak bisa log in\n",
      "2. setiap hari kalo buka aplikasi dana ga bisa terus hrs di update melulu jadi takut nyimpan uang di aplikasi ini\n",
      "3. aplikasi tidak bisa di buka cuma logo aja langsung keluar sendiripadahal baru di update sudah d coba di restart ulng hasilnya tetap sama\n",
      "4. udah lama make dana baru kali ini mau dibuka nggak bisa kembali sendiri meskipun diupdate tetap gak bisa dibuka tolong diperbaiki lagi misalkan ada saldonya ini kan nggak bisa dibuka gimana\n",
      "5. ni aplikasi kenapa dah error mulu mentok dilogo update udah padahal\n"
     ]
    }
   ],
   "source": [
    "keywords = ['cicil', 'saldo', 'login', 'kecewa', 'update']\n",
    "\n",
    "for word in keywords:\n",
    "    print(f\"\\n=== Context for: {word} ===\")\n",
    "    # Taking 5 examples of reviews that contain those words\n",
    "    display_samples = df[df['content_clean'].str.contains(word, case=False, na=False)]['content_clean'].head(5).values\n",
    "    for i, text in enumerate(display_samples):\n",
    "        print(f\"{i+1}. {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd627a7",
   "metadata": {},
   "source": [
    "### **Slang Normalization (Mapping)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab12dce",
   "metadata": {},
   "source": [
    "#### **Step 6: Slang Normalization (Mapping)**\n",
    "App reviews are often written in informal Indonesian (\"Bahasa Gaul\"). I apply a custom slang mapping dictionary to transform abbreviations like 'gx' to 'tidak' and 'ccln' to 'cicilan'. This normalization ensures that the sentiment analysis model can recognize the actual meaning behind the informal text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6821a996",
   "metadata": {},
   "outputs": [],
   "source": [
    "slang_dict = {\n",
    "    # From the findings obtained\n",
    "    \"ccln\": \"cicilan\", \"ccl\": \"cicil\",\n",
    "    \"skrng\": \"sekarang\", \"skrg\": \"sekarang\", \"krg\": \"kurang\",\n",
    "    \"kbnykn\": \"kebanyakan\", \"bnyk\": \"banyak\",\n",
    "    \"klo\": \"kalau\", \"kalo\": \"kalau\",\n",
    "    \"aj\": \"saja\", \"aja\": \"saja\",\n",
    "    \"mw\": \"mau\", \"mo\": \"mau\",\n",
    "    \"sdh\": \"sudah\", \"udh\": \"sudah\", \"dah\": \"sudah\",\n",
    "    \"ndak\": \"tidak\", \"gk\": \"tidak\", \"g\": \"tidak\", \"ga\": \"tidak\", \"gak\": \"tidak\",\n",
    "    \"apl\": \"aplikasi\", \"apk\": \"aplikasi\", \"apklikasi\": \"aplikasi\",\n",
    "    \"notip\": \"notifikasi\",\n",
    "    \"mending\": \"lebih baik\",\n",
    "    \n",
    "    # Emotion/transaction words\n",
    "    \"eror\": \"error\", \"errror\": \"error\",\n",
    "    \"ilang\": \"hilang\", \"raib\": \"hilang\",\n",
    "    \"nyesel\": \"menyesal\",\n",
    "    \"cuih\": \"kecewa\", # Negative emotion interjection\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59d40fe",
   "metadata": {},
   "source": [
    "### **Stopwords Removal (Including Custom Brand Terms)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24083abf",
   "metadata": {},
   "source": [
    "#### **Step 7: Stopwords Removal**\n",
    "Stopwords are common words that appear frequently but don't carry sentiment (e.g., 'dan', 'di'). In this step, I also remove context-specific terms like 'dana' and 'saya' to eliminate \"noise\" from the data, allowing the more meaningful emotional keywords to stand out in the visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d48af0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "\n",
    "factory = StopWordRemoverFactory()\n",
    "# Get the standard Indonesian stopword list\n",
    "stopwords = factory.get_stop_words()\n",
    "\n",
    "# Add specific brand/context words\n",
    "custom_stopwords = stopwords + ['dana', 'saya', 'aplikasi', 'apk', 'nya', 'ya', 'ini', 'itu']\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    return ' '.join([word for word in str(text).split() if word not in custom_stopwords])\n",
    "\n",
    "# Run before stemming\n",
    "df['content_clean'] = df['content_clean'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307b2592",
   "metadata": {},
   "source": [
    "### **Indonesian Language Stemming (Sastrawi)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c128d9cd",
   "metadata": {},
   "source": [
    "#### **Step 8: Indonesian Language Stemming (Sastrawi)**\n",
    "Finally, I use the Sastrawi library to perform stemming. This process reduces words to their root form (e.g., 'mengecewakan' becomes 'kecewa'). Stemming is vital in Indonesian NLP to consolidate various word forms into a single meaningful base, which improves the clustering of sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd24487a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Stemming process... Please wait.\n",
      "Process Completed! Cleaned data is saved to '../data/reviews_dana_cleaned.csv'\n"
     ]
    }
   ],
   "source": [
    "# Initialize Sastrawi Stemmer\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "# Execute Stemming Process\n",
    "# Note: This might take 2-3 minutes for 1000 rows as Sastrawi processes each word\n",
    "print(\"Starting Stemming process... Please wait.\")\n",
    "\n",
    "# Applying stemming to the cleaned content\n",
    "df['content_clean'] = df['content_clean'].apply(lambda x: stemmer.stem(str(x)))\n",
    "\n",
    "# Export the Final Cleaned Data\n",
    "# Saving the result to a new CSV file for Phase 3\n",
    "df.to_csv('../data/reviews_dana_cleaned.csv', index=False)\n",
    "\n",
    "print(\"Process Completed! Cleaned data is saved to '../data/reviews_dana_cleaned.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
